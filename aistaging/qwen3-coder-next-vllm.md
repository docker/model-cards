# Qwen3-Coder-Next

Qwen3-Coder-Next is an open-weight language model designed specifically for coding agents and local development. With only 3B activated parameters out of 80B total parameters, it achieves performance comparable to models with 10–20x more active parameters through an efficient mixture-of-experts (MoE) architecture. This makes it highly cost-effective for agent deployment while maintaining state-of-the-art capabilities.

The model excels at long-horizon reasoning, complex tool usage, and recovery from execution failures, ensuring robust performance in dynamic coding tasks. Through an elaborate training recipe, it demonstrates advanced agentic capabilities that enable it to handle sophisticated development workflows. Its versatile 256K context length, combined with adaptability to various scaffold templates, enables seamless integration with different CLI/IDE platforms such as Claude Code, Qwen Code, Qoder, Kilo, Trae, and Cline.

Qwen3-Coder-Next features a hybrid architecture combining Gated DeltaNet and Gated Attention layers with a large-scale MoE system of 512 experts, where only 10 are activated per token. This design delivers exceptional efficiency while maintaining the reasoning depth required for complex coding tasks. The model supports native 262K token context length and is optimized for real-world IDE integration.

---

## Characteristics

| Attribute | Value |
|---|---|
| **Provider** | Qwen (Alibaba Cloud) |
| **Architecture** | Qwen3NextForCausalLM (Mixture-of-Experts) |
| **Parameters** | 80B total, 3B activated per token |
| **Context Length** | 262,144 tokens (256K) |
| **Input modalities** | Text |
| **Output modalities** | Text |
| **License** | Apache 2.0 |

## Using this model with Docker Model Runner

```bash
docker model run qwen3-coder-next-vllm
```

For more information, check out the [Docker Model Runner docs](https://docs.docker.com/desktop/features/model-runner/).

## Benchmarks

The model achieves competitive performance on coding benchmarks:

| Benchmark | Performance Notes |
|---|---|
| **SWE-bench Verified** | Competitive with models using 10-20x more active parameters |
| **SWE-bench Pro** | Strong performance on professional-grade software engineering tasks |
| **Agentic Coding** | Excels at long-horizon reasoning and complex tool usage |

The model demonstrates particularly strong capabilities in:
- Tool calling and function execution
- Recovery from execution failures
- Multi-turn coding conversations
- Integration with real-world development environments

## Architecture Details

| Component | Specification |
|---|---|
| **Total Parameters** | 80B (79B non-embedding) |
| **Activated Parameters** | 3B per token |
| **Hidden Dimension** | 2,048 |
| **Number of Layers** | 48 |
| **Hybrid Layout** | 12 × (3 × (Gated DeltaNet → MoE) → 1 × (Gated Attention → MoE)) |
| **Gated Attention** | 16 Q heads, 2 KV heads, 256 head dimension |
| **Gated DeltaNet** | 32 V heads, 16 QK heads, 128 head dimension |
| **MoE Configuration** | 512 experts, 10 activated, 1 shared expert |

## Links

- https://huggingface.co/Qwen/Qwen3-Coder-Next
- https://qwen.ai/blog?id=qwen3-coder-next
- https://github.com/QwenLM/Qwen3-Coder
- https://qwen.readthedocs.io/en/latest/

## Considerations

- **Context Length**: The default context length is 256K tokens. If running into memory issues, consider reducing to a smaller value like 32,768 tokens.
- **Hardware Requirements**: Tensor parallelism across multiple GPUs is recommended for optimal performance. Minimum 2 GPUs suggested for deployment.
- **Non-Thinking Mode**: This model supports only non-thinking mode and does not generate `<think></think>` blocks in its output.
- **Tool Calling**: The model requires proper tool call parser configuration (`qwen3_coder`) when deploying with vLLM or SGLang.
- **Sampling Parameters**: For optimal performance, use `temperature=1.0`, `top_p=0.95`, `top_k=40`.
- **Use Case**: Specifically optimized for coding agents and IDE integration rather than general-purpose text generation.

### Generated by
This model card was automatically generated using [cagent-action](https://github.com/docker/cagent-action).
Want to learn more about Docker Model Runner? Check out the project repository: [https://github.com/docker/model-runner](https://github.com/docker/model-runner).
