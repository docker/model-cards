# Qwen3-Coder-Next

Qwen3-Coder-Next is an advanced open-weight language model specifically designed for coding agents and local development environments. This model represents a significant leap forward in efficiency and agentic capabilities, combining a mixture-of-experts (MoE) architecture with just 3B activated parameters (80B total) to deliver performance comparable to models with 10-20x more active parameters. The model excels at long-horizon reasoning, complex tool usage, and recovery from execution failures, making it ideal for building robust coding assistants and agents.

With its 256K context window and hybrid architecture featuring both Gated DeltaNet and Gated Attention mechanisms, Qwen3-Coder-Next offers versatility for integration with real-world IDEs and CLI tools such as Claude Code, Qwen Code, Qoder, Kilo, Trae, and Cline. The model has been trained through an elaborate training recipe that emphasizes agentic capabilities, enabling it to handle dynamic coding tasks with sophisticated tool calling and error recovery.

Built on the Qwen3Next architecture with 512 experts (10 activated per forward pass), this model provides an exceptional balance between performance and computational efficiency, making it highly cost-effective for both local development and agent deployment scenarios.

![Benchmarks](https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/benchmarks.png)

---

## Characteristics

| Attribute | Value |
|---|---|
| **Provider** | Qwen (Alibaba Cloud) |
| **Architecture** | Qwen3NextForCausalLM (MoE with Gated DeltaNet & Attention) |
| **Languages** | Multilingual |
| **Input modalities** | Text |
| **Output modalities** | Text |
| **Context Length** | 262,144 tokens (256K) |
| **Total Parameters** | 80B (3B activated, 79B non-embedding) |
| **Number of Experts** | 512 (10 activated + 1 shared) |
| **License** | Apache-2.0 |

## Using this model with Docker Model Runner

```bash
docker model run qwen3-coder-next-vllm
```

For more information, check out the [Docker Model Runner docs](https://docs.docker.com/desktop/features/model-runner/).

## Benchmarks

Qwen3-Coder-Next demonstrates exceptional performance across coding benchmarks, particularly excelling in agentic coding tasks. The model has been evaluated on SWE-bench Pro and various other coding evaluation suites, showing competitive results with significantly larger models while maintaining a small active parameter count.

![SWE-bench Pro Results](https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/swebench_pro.png)

## Architecture Details

The model features a unique hybrid architecture:
- **48 Layers Total** with hybrid layout: 12 × (3 × (Gated DeltaNet → MoE) → 1 × (Gated Attention → MoE))
- **Gated Attention**: 16 attention heads for Q, 2 for KV with 256 head dimension
- **Gated DeltaNet**: 32 linear attention heads for V, 16 for QK with 128 head dimension
- **MoE Configuration**: 512 experts with 10 activated per forward pass plus 1 shared expert
- **Hidden Dimension**: 2048
- **Rotary Position Embedding**: 64 dimensions

## Links

- https://huggingface.co/Qwen/Qwen3-Coder-Next
- https://qwen.ai/blog?id=qwen3-coder-next
- [GitHub Repository](https://github.com/QwenLM/Qwen3-Coder)
- [Documentation](https://qwen.readthedocs.io/en/latest/)
- [Technical Report](https://github.com/QwenLM/Qwen3-Coder/blob/main/qwen3_coder_next_tech_report.pdf)

## Considerations

- **Context Length Management**: The default 256K context length may require significant memory. Consider reducing to 32K tokens (32,768) if you encounter out-of-memory issues during deployment.
- **Hardware Requirements**: While highly efficient for its size, the model benefits from multi-GPU tensor parallelism for optimal performance. The model requires careful hardware planning for production deployments.
- **Tool Calling**: The model excels at tool calling but requires proper tool definition and integration. Follow the recommended sampling parameters (temperature=1.0, top_p=0.95, top_k=40) for optimal performance.
- **Non-Thinking Mode**: This model operates exclusively in non-thinking mode and does not generate `<think></think>` blocks in its output.
- **Deployment Framework**: Requires `sglang>=0.5.8` or `vllm>=0.15.0` for production deployment with proper tool calling support.

### Generated by
This model card was automatically generated using [cagent-action](https://github.com/docker/cagent-action).
Want to learn more about Docker Model Runner? Check out the project repository: [https://github.com/docker/model-runner](https://github.com/docker/model-runner).
